{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb51866a-5ffb-43fd-9784-be85a50a2987",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec96b34f-1138-42f1-8920-5d0c200656be",
   "metadata": {},
   "source": [
    "A plataforma web de aprendizagem interativa [freeCodeCamp](https://www.freecodecamp.org/) publicou o excelente curso desenvolvido pela engenheira e cientista graduada pelo MIT, [Kylie Ying](https://www.kylieying.com/), intitulado **Machine Learning for Everybody** – [Full Course](https://www.youtube.com/watch?v=i_LwzRVP7bg). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be7c028-88c9-41ea-80ca-76b3916306e9",
   "metadata": {},
   "source": [
    "## Classificação binária"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccffac5-84df-48a5-86d0-845a800f700e",
   "metadata": {},
   "source": [
    "No início do curso, foi abordado um problema de aprendizado supervisionado, para classificação binária, em que o modelo aprende com dados de treinamento devidamente rotulados, para no fim ser colocado à prova com os dados de teste, após o ajuste com dados de validação. O modelo deve classificar as partículas, a partir das características fornecidas pelas *features*, em raios gama(*sinal*) ou hadron(*fundo*). \n",
    "\n",
    "Foram utilizados diversos algoritmos de classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f6a74a-3b3e-4c34-b048-7d469bd52984",
   "metadata": {},
   "source": [
    "### Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20610b7d-3d37-4174-aeb7-e110fc092af3",
   "metadata": {},
   "source": [
    "Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "Donated by:\n",
    "P. Savicky\n",
    "Institute of Computer Science, AS of CR\n",
    "Czech Republic\n",
    "savicky '@' cs.cas.cz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dc7065-d1a9-43fb-9599-89b3bbafef00",
   "metadata": {},
   "source": [
    "O dataset *MAGIC Gamma Telescope* foi gerado com o método de simulação denominado *Monte Carlo*, utilizado para reproduzir indiretamente as características dos raios gama que teriam provocado as chuvas eletromagnéticas na atmosfera. Esse método é particularmente eficaz para modelar sistemas complexos e estocásticos, como as interações de partículas de alta energia na atmosfera, permitindo a simulação detalhada dos processos físicos envolvidos e a coleta de dados sobre as características esperadas das chuvas eletromagnéticas geradas pelos raios gama.\n",
    "\n",
    "O artigo original que relata a simulação pode ser obtido em: https://inspirehep.net/literature/469835"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e99956-6a8e-4cce-bc87-433aaabc4106",
   "metadata": {},
   "source": [
    "## Radiação Cherenkov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457c5f2a-3876-4001-b39c-4ba255b2294b",
   "metadata": {},
   "source": [
    "Os telescópios Cherenkov são baseados no solo e os raios gama são absorvidos pela atmosfera da Terra antes de alcançarem a superfície. Esses telescópios detectam a radiação Cherenkov produzida quando os raios gama interagem com a atmosfera, criando chuvas de partículas secundárias. Esse método indireto permite estudar os raios gama de alta energia de forma segura e eficaz.\n",
    "\n",
    "**Radiação Cherenkov**, em homenagem físico russo e soviético, Nobel de Física em 1958, *Pavel Alexeevitch Tcherenkov*, é a luz emitida quando uma partícula carregada, como um elétron, viaja através de um meio (como água ou ar) a uma velocidade superior à velocidade da luz. Este fenômeno é análogo ao *boom* sônico produzido por um objeto que viaja mais rápido que a velocidade do som no ar. A radiação Cherenkov é emitida em um ângulo característico em relação à direção da partícula, formando um cone de luz azulada, que pode ser detectado por dispositivos especializados, como telescópios Cherenkov atmosféricos, para estudar partículas de alta energia e suas interações.\n",
    "\n",
    "Alguns dispositivos foram desenvolvidos para a observação direta dos raios gama na atmosfera e além, incluindo telescópios de raios gama espaciais, colocados em órbita acima da atmosfera terrestre, onde podem detectar diretamente os raios gama sem interferência atmosférica. Citamos alguns exemplos:\n",
    "\n",
    "**Telescópio Espacial de Raios Gama Fermi**: Lançado pela NASA, este telescópio detecta raios gama de alta energia.\n",
    "\n",
    "**Observatório de Raios Gama Compton**: Um observatório de raios gama que operou de 1991 a 2000.\n",
    "\n",
    "**Balões Estratosféricos**: Equipados com detectores de raios gama, esses balões são lançados até a estratosfera, onde a densidade atmosférica é muito menor, permitindo a observação direta dos raios gama. Exemplos de missões incluem:\n",
    "\n",
    "**Observações com Balões de Alta Altitude**: Programas de balões da NASA e outras agências espaciais que transportam detectores para altitudes onde a interferência atmosférica é mínima.\n",
    "\n",
    "Esses instrumentos foram projetados para operar fora da influência da densa atmosfera terrestre, permitindo a detecção direta e o estudo dos raios gama provenientes de fontes cósmicas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56de4cc-30ae-4d6d-976c-1ceacd945c8e",
   "metadata": {},
   "source": [
    "## Processo de modelagem padrão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372bb491-b5b6-45ce-bf96-60ad58dbf0b4",
   "metadata": {},
   "source": [
    "Em um processo de modelagem padrão, utilizamos dados de validação para ajustar o modelo, especialmente quando estamos testando diferentes algoritmos ou ajustando hiperparâmetros. Somente após escolher o melhor modelo com base nos dados de validação é que utilizamos os dados de teste para avaliar a performance final.\n",
    "\n",
    "Um fluxo de trabalho adequado deve garantir que os dados de validação sejam usados adequadamente para ajustar o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a997e5c0-a9ee-4cea-a67a-fe8c5b0ab95f",
   "metadata": {},
   "source": [
    "Ao usar os dados de validação, você pode ajustar hiperparâmetros e selecionar o melhor modelo sem contaminar os dados de teste, que devem ser usados apenas para a avaliação final. Se você estiver testando múltiplos modelos, pode repetir o processo de treinamento e validação para cada modelo, comparando seus desempenhos nos dados de validação para decidir qual modelo será avaliado nos dados de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce11b42d-bfe8-4926-8d9e-21df2a7f8dd3",
   "metadata": {},
   "source": [
    "\n",
    "De outra sorte, para que subdividir o dataset em *treinamento*, *validação* e *teste*?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f2ca72-f467-43ae-a073-05235e162bcd",
   "metadata": {},
   "source": [
    "## Importamos as bilbiotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de2021c3-ec76-4f03-a299-5b5b3d4f4908",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165e53ee-8517-42f4-9eb3-1c9bdb745669",
   "metadata": {},
   "source": [
    "## Carregamos o dataset\n",
    "### Renomeamos as colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a0d624e-720f-434f-af63-5b3d47a78105",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'magic04.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfLength\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfWidth\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfSize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfConc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfConc1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfAsym\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfM3Long\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfM3Trans\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfAlpha\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfDist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmagic04.data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'magic04.data'"
     ]
    }
   ],
   "source": [
    "cols = [\"fLength\", \"fWidth\", \"fSize\", \"fConc\", \"fConc1\", \"fAsym\", \"fM3Long\", \"fM3Trans\", \"fAlpha\", \"fDist\", \"class\"]\n",
    "df = pd.read_csv(\"magic04.data\", names=cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e6ca56-323e-4176-8835-fba5da88fec7",
   "metadata": {},
   "source": [
    "## Transformamos a variável categórica em numérica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fdeb68-fa8d-4d68-bb2f-b8295c980061",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"] = (df[\"class\"] == \"g\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec096d25-4f81-4453-b981-f49b9fc5ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1190a57e-34a5-4402-834f-dac2c1e7c893",
   "metadata": {},
   "source": [
    "## Visualizamos as distribuições "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65289c79-d9be-4d49-9e57-dfdf6023efe8",
   "metadata": {},
   "source": [
    "**Criamos uma matriz de gráficos de dispersão:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599246db-3f56-4225-a8cc-fabe1f32e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "dados = df.iloc[:, :-1].copy()\n",
    "sns.pairplot(data=dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c20c72c-b7af-4f67-bb69-017262a4a114",
   "metadata": {},
   "source": [
    "**Calculamos a matriz de correlação:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcddde59-3d2f-4692-aa94-6271fcf33c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.drop(labels='class',axis=1).corr()\n",
    "sns.heatmap(data=corr,xticklabels=corr.columns,yticklabels=corr.columns,linewidths=0.5,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be271374-ca5c-4c07-b0df-b7f2bbb14e26",
   "metadata": {},
   "source": [
    "### Separação do dataset em treinamento, validação e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f773c0-d9a5-4613-9722-cf917e5c3da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "train, valid, test = np.split(df.sample(frac=1), [int(0.6*len(df)), int(0.8*len(df))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c660a39b-79f3-4873-b568-161098ba6730",
   "metadata": {},
   "source": [
    "### Conferimos o balanceamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd5192-7423-41cf-9d6f-7e64830cc096",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train[train[\"class\"]==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9dec7c-4fbe-453d-a00d-c08736e9b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train[train[\"class\"]==0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba3a91-1286-4ca0-9ebe-f1b059c4225a",
   "metadata": {},
   "source": [
    "## Padronização e balanceamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e64b19-a8d9-4bbf-bf6d-50d08804d519",
   "metadata": {},
   "source": [
    "Além da padronização dos dados, utilizamos o método *RandomOverSampler* para reamostragem dos dados desbalanceados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962e0d72-99d5-4933-a8c9-a2da343e4bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def scale_dataset(dataframe, oversample=False):\n",
    "      X = dataframe[dataframe.columns[:-1]].values\n",
    "      y = dataframe[dataframe.columns[-1]].values\n",
    "    \n",
    "      scaler = StandardScaler()\n",
    "      X = scaler.fit_transform(X)\n",
    "    \n",
    "      if oversample:\n",
    "        ros = RandomOverSampler()\n",
    "        X, y = ros.fit_resample(X, y)\n",
    "    \n",
    "      data = np.hstack((X, np.reshape(y, (-1, 1))))\n",
    "    \n",
    "      return data, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58e2ad7-596d-41cd-bf41-6a8777a4d15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, X_train, y_train = scale_dataset(train, oversample=True)\n",
    "valid, X_valid, y_valid = scale_dataset(valid, oversample=False)\n",
    "test, X_test, y_test = scale_dataset(test, oversample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832b5114-c739-4060-b441-b5294987d207",
   "metadata": {},
   "source": [
    "# Algoritmos de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326a5c3d-a10b-452a-954f-abc1a2ab4e13",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6583be2a-bcbd-4449-b9d2-2c6e91592c3e",
   "metadata": {},
   "source": [
    "O KNN é um algoritmo de aprendizado supervisionado que classifica uma nova amostra com base na maioria dos \"vizinhos\" mais próximos. Neste caso, utilizamos `k=5`, o que significa que a classificação de uma nova amostra será baseada nas 5 amostras mais próximas no espaço dos recursos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3ac17b-022c-4b0c-bf96-0f7a4520bf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ec929d-9a44-4786-b8be-8d85b0a5043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd53b898-2f74-4750-b962-e72ab7e4e3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = knn_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753e721b-68b0-4000-94cb-e108d28ca7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d79655c-a7eb-46c0-b7b1-b70014e16be6",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba0c84f-6df5-4740-b1cb-3869e8291598",
   "metadata": {},
   "source": [
    "O Naive Bayes é baseado no teorema de Bayes, que assume independência entre os predictores. Este modelo é útil para problemas de classificação binária e multiclasse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5071cf78-b7fd-424c-bfe3-bcea071a0dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0ebf28-26c6-4a0e-b912-472069e65f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model = nb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e135e1-c1b2-413d-82ec-b33a295e8f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = nb_model.predict(X_valid)\n",
    "print(classification_report(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c182468-36e0-423a-ad9f-5aaf534061b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bb14e8-a01f-448d-9506-d6538d6c0a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ac585d-f725-4447-8495-fc780c912e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_model = LogisticRegression()\n",
    "lg_model = lg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f2071-8c90-4444-9c05-cd955187c89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = lg_model.predict(X_valid)\n",
    "print(classification_report(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b98d23-65df-4f93-a13a-b07ac4b313de",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b956f0-da5b-4110-821f-d4cf9b26af02",
   "metadata": {},
   "source": [
    "O SVM é um algoritmo que encontra um hiperplano que melhor separa as classes de dados. Utilizamos o SVM para garantir uma separação máxima entre as classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ecdc3d-bc7c-4846-9d1f-28d1f105008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89fb912-9de4-4729-907b-3e16422706df",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC()\n",
    "svm_model = svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5bb443-cd98-4fd2-ba17-83545e5b716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = svm_model.predict(X_valid)\n",
    "print(classification_report(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b2a1c-8b59-4638-a7a0-69e7e9f05ba0",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eb4b0e-4099-4644-8179-a8340fc394d3",
   "metadata": {},
   "source": [
    "A Regressão Logística é um modelo estatístico utilizado para problemas de classificação binária. Ela estima a probabilidade de uma variável dependente pertencer a uma determinada classe com base em uma ou mais variáveis independentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af014e04-e362-4ad0-87c8-9b515d767739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f5e578-2e51-4d65-af34-70d9d4ee64e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fa405c-2291-463d-a06e-d2f219249d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = logreg_model.predict(X_valid)\n",
    "print(classification_report(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874a5f2b-d97e-4ae0-8814-607a3b93ae7e",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5019fa05-0bd5-4307-9e36-48e6764bb77a",
   "metadata": {},
   "source": [
    "O Random Forest é um conjunto de múltiplas árvores de decisão, onde cada árvore é treinada com uma amostra diferente do dataset. Ele é conhecido por melhorar a precisão e reduzir o overfitting ao combinar as previsões de várias árvores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab3ed27-2164-4d97-93ce-e707c5715fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a4011-de47-48ea-bd12-3093f2af6c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689f9e70-786a-46db-888b-14bc66ea20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = rf_model.predict(X_valid)\n",
    "print(classification_report(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e603d-e8e9-46d7-bea9-6430b5a8984b",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104f2484-5f77-470b-91d4-1ce31ea815af",
   "metadata": {},
   "source": [
    "O AdaBoost é um algoritmo de ensemble que combina a performance de múltiplos classificadores fracos para formar um classificador forte. Ele ajusta iterativamente os pesos das instâncias para focar nos erros mais difíceis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6385d43d-52b8-43c7-8088-1f71b3628fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d054fb07-ba6e-4ded-be8f-d7cf73e7f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_model = AdaBoostClassifier(n_estimators=50)\n",
    "ada_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ed53bb-b012-4368-9f5f-3c2a8be04157",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = ada_model.predict(X_valid)\n",
    "print(classification_report(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe36eaa-c3c3-42ef-834b-6123e39c7722",
   "metadata": {},
   "source": [
    "## Escolha do modelo para teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90a6999-ca69-4a0e-b8be-b9bd7ae8d412",
   "metadata": {},
   "source": [
    "Escolhemos o modelo que apresentou melhor desempenho durante a fase de validação, para submeter os dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5349798-19d3-457b-815f-0ec9c9a37d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = rf_model.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847df0da-a551-43de-8465-9597c9d3691a",
   "metadata": {},
   "source": [
    "## Principais métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b3d924-d402-4ae9-8375-25cb2062e045",
   "metadata": {},
   "source": [
    "A seguir, explicamos os principais indicadores fornecidos pelo *classification_report* do *sklearn*:\n",
    "\n",
    "1. **Precision (Precisão)**:\n",
    "A precisão é a proporção de verdadeiros positivos entre as previsões positivas feitas pelo modelo. Ou seja, ela mede a exatidão das previsões positivas do modelo.\n",
    "\n",
    "$$ \\text{Precisão} = \\frac{\\text{Verdadeiros Positivos (VP)}}{\\text{Verdadeiros Positivos (VP)} + \\text{Falsos Positivos (FP)}} $$\n",
    "\n",
    "\n",
    "\n",
    "2. **Recall (Recall/Sensibilidade)**:\n",
    "O recall é a proporção de verdadeiros positivos entre todas as amostras que realmente pertencem à classe positiva. Ele mede a capacidade do modelo de encontrar todas as instâncias positivas.\n",
    "\n",
    "$$ \\text{Recall} = \\frac{\\text{Verdadeiros Positivos (VP)}}{\\text{Verdadeiros Positivos (VP)} + \\text{Falsos Negativos (FN)}} $$\n",
    "\n",
    "\n",
    "\n",
    "3. **F1-score**:\n",
    "O F1-score é a média harmônica entre precisão e recall. Ele fornece uma única métrica que balanceia ambos, sendo útil especialmente quando há um desequilíbrio entre classes.\n",
    "\n",
    "$$ \\text{F1-score} = 2 \\times \\frac{\\text{Precisão} \\times \\text{Recall}}{\\text{Precisão} + \\text{Recall}} $$\n",
    "\n",
    "\n",
    "\n",
    "4. **Support**:\n",
    "O suporte é o número de ocorrências reais de cada classe no dataset. Ele indica a quantidade de instâncias que cada classe possui no conjunto de dados de teste.\n",
    "\n",
    "$$ \\text{Support} = \\text{Número de exemplos da classe} $$\n",
    "\n",
    "\n",
    "\n",
    "6. **Accuracy (Acurácia)**:\n",
    "A acurácia é a proporção de previsões corretas (tanto verdadeiros positivos quanto verdadeiros negativos) em relação ao total de previsões feitas. Ela fornece uma visão geral do desempenho do modelo.\n",
    "\n",
    "$$ \\text{Acurácia} = \\frac{\\text{Verdadeiros Positivos (VP)} + \\text{Verdadeiros Negativos (VN)}}{\\text{Total de Exemplos}} $$\n",
    "\n",
    "​\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bd3845-8f4c-498e-9dcd-308325be0e48",
   "metadata": {},
   "source": [
    "### Indicadores do modelo Random Forest, na fase de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59676b7-d273-4d21-ae51-b819e3ad8627",
   "metadata": {},
   "source": [
    "**Classe 0:**\n",
    "\n",
    "Precisão: 0.82 (82% das previsões para a classe 0 estavam corretas)<br>\n",
    "Recall: 0.80 (80% das instâncias reais da classe 0 foram corretamente identificadas)<br>\n",
    "F1-score: 0.81 (média harmônica de precisão e recall para a classe 0)<br>\n",
    "Support: 1305 (há 1305 instâncias reais da classe 0 no dataset de teste)\n",
    "\n",
    "\n",
    "**Classe 1:**\n",
    "\n",
    "Precisão: 0.90 (90% das previsões para a classe 1 estavam corretas)<br>\n",
    "Recall: 0.91 (91% das instâncias reais da classe 1 foram corretamente identificadas)<br>\n",
    "F1-score: 0.90 (média harmônica de precisão e recall para a classe 1)<br>\n",
    "Support: 2499 (há 2499 instâncias reais da classe 1 no dataset de teste)<br>\n",
    "Acurácia Geral: 0.87 (87% das previsões totais estavam corretas)\n",
    "\n",
    "**Macro Average (média das métricas por classe):**\n",
    "\n",
    "Precisão: 0.86<br>\n",
    "Recall: 0.85<br>\n",
    "F1-score: 0.86\n",
    "\n",
    "**Weighted Average** (média ponderada das métricas, considerando o suporte de cada classe):<br>\n",
    "\n",
    "Precisão: 0.87<br>\n",
    "Recall: 0.87<br>\n",
    "F1-score: 0.87<br>\n",
    "\n",
    "Esses indicadores mostram que o modelo RandomForestClassifier teve um bom desempenho, com uma acurácia de 87% e valores altos de precisão, recall e F1-score para ambas as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f2d566-7f27-42d6-899d-890c63ba60d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
